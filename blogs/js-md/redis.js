var defaultItem = 'prometheus-1-introduction'
var jsObj ={
	'prometheus-1-introduction':{
		'title':'Introduction of Prometheus',
		'content':"**本系列文章不赘述官网中的一些无关紧要的内容**\n\n官方文档：https://prometheus.io/docs/introduction/overview/\n\n### 什么是Prometheus \n\n**Prometheus is an open-source systems monitoring and alerting toolkit.（开源的系统监控和报警套件）**\n\n### 特性（Features）\n- a multi-dimensional data model with time series data identified by metric name and key/value pairs（带有时间序列数据的多维数据模型，由指标名称和键值对标记）\n- a flexible query language to leverage this dimensionality（灵活的查询语言获取维度信息）\n- no reliance on distributed storage; single server nodes are autonomous（无分布式存储依赖，自治的单一服务节点）\n- time series collection happens via a pull model over HTTP（使用http协议的pull模式实现时间序列数据采集）\n- pushing time series is supported via an intermediary gateway（时间序列推送由中间接口支持）\n- targets are discovered via service discovery or static configuration（可自动发现或者静态配置的目标端点）\n- multiple modes of graphing and dashboarding support（混合图形模型和面板支持）\n\n### 组件（Components）\n**The Prometheus ecosystem consists of multiple components, many of which are optional:**\n\n- the main Prometheus server which scrapes and stores time series data（主服务抓取并存储时间序列数据）\n- client libraries for instrumenting application code（客户端库可用来检测应用代码）\n- a push gateway for supporting short-lived jobs（推送接口用来支持短期工作）\n- special-purpose exporters for services like HAProxy, StatsD, Graphite, etc.（特定用途的输出器，如HAProxy, StatsD, Graphite等）\n- an alertmanager to handle alerts（处理报警的alertmanager）\n- various support tools（对于各种工具的支持）\n### 架构（Architecture）\n![这里写图片描述](https://prometheus.io/assets/architecture.svg)\n\n对于上图做一下解释：\n\n\t左上：通过推送接口获取短活任务/服务的监控指标，然后由prometheus自动抓取\n\t左下：通过任务/输出器或者prometheus server暴露接口提供监控指标，然后由prometheus自动抓取\n\t中上：自动服务发现组件\n\t中下：prometheus服务器，实现服务发现、数据查询存储等功能\n\t右上：将prometheus推送过来的报警信息由alertmanager处理后发送到指定接收端\n\t右下：通过web端界面或者客户端获取数据进行展示，也可以提供服务配置、规则配置、报警接收等\n\n### prometheus适合什么时候使用（When does it fit?）\n\n\t适合记录单纯的数据时间序列，既适合机器中心的监控又适合高动态面向服务的架构。在微服务世界里，提供强有力的多维数据收集与查询 。\n\tPrometheus为可靠性而设计，使得我们能够在系统中断的时候快速诊断问题所在。每一台prometheus服务器都是独立的，不依赖于任何的网络存储或者远程服务，就算其他的部分基础设施down掉了你也可以依靠它，不需要搭建额外的基础设施去使用它。\n\n###  prometheus不适合什么时候使用（When does it not fit?）\n\n\tPrometheus重在可靠性，任何时候我们都可以查看系统的那些资料可用，即使在失败情况下。如果需要100%的准确性，例如对每一个请求的计费，Prometheus不是最好的选择，这种情况下你需要使用其它系统来收集和分析数据来计费，剩下的监控任务就交给prometheus。\n\n\n关于安装不赘述请参阅官网：\nhttps://prometheus.io/docs/introduction/first_steps/\n下篇将注重于配置解读\n",
		'date':' on Jan 2, 2018'
	},
	'prometheus-2-configuration':{
		'title':'Configuration of Prometheus',
		'content':"### prometheus配置解读\n\n**Prometheus configuration is YAML**，本文将以一个[示例配置](https://github.com/prometheus/prometheus/edit/release-2.1/config/testdata/conf.good.yml)来进行解读\n\n\n[官方配置在此，英文要好](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)\n```\n#全局配置将应用到所有的配置项上去，对于具体配置项中的同一配置将重写全局配置\nglobal:\n  scrape_interval:     15s\n  #抓取间隔，即prometheus server从给定输出器/端口获取指标的时间间隔\n  evaluation_interval: 30s\n  #评估间隔，即prometheus server对抓取到的指标进行评估的时间间隔\n  # scrape_timeout is set to the global default (10s).\n  #抓取的超时时间被设置为10s\n\n  external_labels:\n  #外部标签，自定义键值对，可多个\n    monitor: codelab\n    foo:     bar\n\nrule_files:\n#规则读取文件或者路径，可多个，支持一定的正则匹配，后文将附上一般规则文件格式示例\n- \"first.rules\"\n- \"my/*.rules\"\n\nremote_write:\n#远程写入，将本台服务器收集到的数据写到另外的主机上去，可以对部分标签执行具体的动作\n  - url: http://remote1/push\n    write_relabel_configs:\n    - source_labels: [__name__]\n      regex:         expensive.*\n      action:        drop\n  - url: http://remote2/push\n\nremote_read:\n#远程读取，从其他主机获取抓取的指标，可以指明具体的服务/任务（通过标签来过滤）\n  - url: http://remote1/read\n    read_recent: true\n  - url: http://remote3/read\n    read_recent: false\n    required_matchers:\n      job: special\n\nscrape_configs:\n#抓取的配置\n- job_name: prometheus\n  honor_labels: true#用来解决抓取到的数据与服务器端标签冲突的情况，设置为true则保留抓取到的数据的标签，否则应用抓取对象+服务端标签\n  # scrape_interval is defined by the configured global (15s).\n  # scrape_timeout is defined by the global default (10s).\n\n  # metrics_path defaults to '/metrics'\n  # scheme defaults to 'http'.\n\n  file_sd_configs:\n  #通过指定的文件或者路径进行自动服务.目标发现，一般需要执行reload才能生效，后文将对文件格式做示例讲解\n    - files:\n      - foo/*.slow.json\n      - foo/*.slow.yml\n      - single/file.yml\n      refresh_interval: 10m\n    - files:\n      - bar/*.yaml\n\n  static_configs:\n  #服务/目标的静态配置，格式如下，列表中包含的是端点\n  - targets: ['localhost:9090', 'localhost:9191']\n    labels:#目标标签，自定义键值对，可多个\n      my:   label\n      your: label\n\n  relabel_configs:#标签重写配置\n  - source_labels: [job, __meta_dns_name]#源标签\n    regex:         (.*)some-[regex]#正则匹配\n    target_label:  job#目标标签\n    replacement:   foo-${1}#替换值\n    # action defaults to 'replace'\n  - source_labels: [abc]\n    target_label:  cde\n  - replacement:   static\n    target_label:  abc\n  - regex:\n    replacement:   static\n    target_label:  abc\n\n  bearer_token_file: valid_token_file\n\n\n- job_name: service-x\n\n  basic_auth:#对于需要进行认证的服务进行的认证设置\n    username: admin_name\n    password: \"multiline\\nmysecret\\ntest\"\n\n  scrape_interval: 50s\n  scrape_timeout:  5s\n\n  sample_limit: 1000\n\n  metrics_path: /my_path\n  scheme: https\n\n  dns_sd_configs:\n  - refresh_interval: 15s\n    names:\n    - first.dns.address.domain.com\n    - second.dns.address.domain.com\n  - names:\n    - first.dns.address.domain.com\n    # refresh_interval defaults to 30s.\n\n  relabel_configs:\n  - source_labels: [job]\n    regex:         (.*)some-[regex]\n    action:        drop\n  - source_labels: [__address__]\n    modulus:       8\n    target_label:  __tmp_hash\n    action:        hashmod\n  - source_labels: [__tmp_hash]\n    regex:         1\n    action:        keep\n  - action:        labelmap\n    regex:         1\n  - action:        labeldrop\n    regex:         d\n  - action:        labelkeep\n    regex:         k\n\n  metric_relabel_configs:\n  - source_labels: [__name__]\n    regex:         expensive_metric.*\n    action:        drop\n\n- job_name: service-y\n\n  consul_sd_configs:\n  - server: 'localhost:1234'\n    token: mysecret\n    services: ['nginx', 'cache', 'mysql']\n    scheme: https\n    tls_config:\n      ca_file: valid_ca_file\n      cert_file: valid_cert_file\n      key_file:  valid_key_file\n      insecure_skip_verify: false\n\n  relabel_configs:\n  - source_labels: [__meta_sd_consul_tags]\n    separator:     ','\n    regex:         label:([^=]+)=([^,]+)\n    target_label:  ${1}\n    replacement:   ${2}\n\n- job_name: service-z\n\n  tls_config:\n    cert_file: valid_cert_file\n    key_file: valid_key_file\n\n  bearer_token: mysecret\n\n- job_name: service-kubernetes\n\n  kubernetes_sd_configs:\n  - role: endpoints\n    api_server: 'https://localhost:1234'\n\n    basic_auth:\n      username: 'myusername'\n      password: 'mysecret'\n\n- job_name: service-kubernetes-namespaces\n\n  kubernetes_sd_configs:\n  - role: endpoints\n    api_server: 'https://localhost:1234'\n    namespaces:\n      names:\n        - default\n\n- job_name: service-marathon\n  marathon_sd_configs:\n  - servers:\n    - 'https://marathon.example.com:443'\n\n    tls_config:\n      cert_file: valid_cert_file\n      key_file: valid_key_file\n\n- job_name: service-ec2\n  ec2_sd_configs:\n    - region: us-east-1\n      access_key: access\n      secret_key: mysecret\n      profile: profile\n\n- job_name: service-azure\n  azure_sd_configs:\n    - subscription_id: 11AAAA11-A11A-111A-A111-1111A1111A11\n      tenant_id: BBBB222B-B2B2-2B22-B222-2BB2222BB2B2\n      client_id: 333333CC-3C33-3333-CCC3-33C3CCCCC33C\n      client_secret: mysecret\n      port: 9100\n\n- job_name: service-nerve\n  nerve_sd_configs:\n    - servers:\n      - localhost\n      paths:\n      - /monitoring\n\n- job_name: 0123service-xxx\n  metrics_path: /metrics\n  static_configs:\n    - targets:\n      - localhost:9090\n\n- job_name: 測試\n  metrics_path: /metrics\n  static_configs:\n    - targets:\n      - localhost:9090\n\n- job_name: service-triton\n  triton_sd_configs:\n  - account: 'testAccount'\n    dns_suffix: 'triton.example.com'\n    endpoint: 'triton.example.com'\n    port: 9163\n    refresh_interval: 1m\n    version: 1\n    tls_config:\n      cert_file: testdata/valid_cert_file\n      key_file: testdata/valid_key_file\n\nalerting:#配置接收报警的alertmanager，端点可以是多个\n  alertmanagers:\n  - scheme: https\n    static_configs:\n    - targets:\n      - \"1.2.3.4:9093\"\n      - \"1.2.3.5:9093\"\n      - \"1.2.3.6:9093\"\n\n```\n\n规则格式：\nhttps://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n\n示例配置\n```\ngroups:#规则组\n- name: example#第一个组名\n  rules:#组内规则，下面的报警规则可以是多个，以下列出两个\n  - alert: HighErrorRate1\n    expr: job:request_latency_seconds:mean5m{job=\"myjob\"} > 0.5\n    for: 10m\n    labels:\n      severity: page\n    annotations:\n      summary: High request latency\n  - alert: HighErrorRate2\n    expr: job:request_latency_seconds:mean5m{job=\"yourjob\"} > 0.5\n    for: 10m\n    labels:\n      severity: page\n    annotations:\n      summary: High request latency\n```\n\n服务配置，示例配置，json格式，服务以列表形式，服务内目标也以列表形式：\n```\n[\n{\n\t\"targets\": [\n\t\t\"127.0.0.1:9104\"\n\t],\n\t\"labels\": {\n\t\t\"job\":\"job1\",\n\t\t\"service\":\"service1\"\n\t}\n},\n{\n        \"targets\": [\n                \"127.0.0.1:9105\"，\n                \"127.0.0.1:9106\"，\n                \"127.0.0.1:9107\"\n        ],\n        \"labels\": {\n                \"job\":\"job2\",\n                \"service\":\"service2\"\n        }\n}\n]\n\n```\n\n另外需要注意的一点是关于prometheus配置重载：\n\n    Prometheus can reload its configuration at runtime. If the new configuration is not well-formed, the changes will not be applied. A configuration reload is triggered by sending a SIGHUP to the Prometheus process or sending a HTTP POST request to the /-/reload endpoint (when the --web.enable-lifecycle flag is enabled). This will also reload any configured rule files.\n\n**如果想要通过向端点发送重载请求来实现服务配置重载那么我们需要在运行程序的时候添加参数如下（两种运行方式）：**\n\n```\n命令行启动\nnohup ./prometheus --web.enable-lifecycle --config.file=prometheus.yml &\n\n或者修改服务启动文件：\n\"/usr/lib/systemd/system/prometheus.service\"\n# -*- mode: conf -*-\n\n[Unit]\nDescription=The Prometheus monitoring system and time series database.\nDocumentation=https://prometheus.io\nAfter=network.target\n\n[Service]\nEnvironmentFile=-/etc/default/prometheus\nUser=prometheus\nExecStart=/usr/bin/prometheus \\\n          --web.enable-lifecycle \\##注意这一行默认没有的，需要加上才能开启Lifecycle APIs\n          --config.file=/etc/prometheus/prometheus.yml \\\n          --storage.tsdb.path=/var/lib/prometheus/data \\\n          --web.console.libraries=/usr/share/prometheus/console_libraries \\\n          --web.console.templates=/usr/share/prometheus/consoles \\\n          $PROMETHEUS_OPTS\nExecReload=/bin/kill -HUP $MAINPID\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target               \n```\n\n**要使prometheus的配置重载有两种方法：**\n\n一：发送SIGHUP信号给应用程序的主进程：\n\n\tkill -1 pid\n\n二：发送post请求给指定端点：\n\n\tcurl -XPOST http://ip:9090/-/reload\n\t#对于此种方法要注意在启动时加上以上所说的--web.enable-lifecycle启动参数\n",
		'date':' on Feb 1, 2018'
	},
	'prometheus-3-webui':{
		'title':'Webui of Prometheus',
		'content':"本文将结合配置和web界面对prometheus的基本使用做示例解说\n### 首先来看一下初始配置\n\n**prometheus.yml**\n```\n# my global config\nglobal:\n  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\n  # scrape_timeout is set to the global default (10s).\n\n# Alertmanager configuration\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n       - localhost:9093\n\n# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.\nrule_files:\n   - \"/etc/prometheus/rules/*.yml\"\n  # - \"second_rules.yml\"\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it's Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\n  - job_name: 'prometheus'\n\n    # metrics_path defaults to '/metrics'\n    # scheme defaults to 'http'.\n\n    static_configs:\n      - targets: ['localhost:9090']\n\n```\n\n\t在prometheus的基本配置中我们指定了Alertmanager为本地的Alertmanager；并且添加了一个服务，服务的端点只有一个，即prometheus自己；指定的报警规则读取路径为/etc/prometheus/rules/*.yml，稍后我们将会向这个路径中添加规则\n\t\n\n**alertmanager.yml**\n```\nglobal:\n  # The smarthost and SMTP sender used for mail notifications.\n  smtp_smarthost: 'localhost:25'\n  smtp_from: 'alertmanager@example.org'\n  smtp_auth_username: 'alertmanager'\n  smtp_auth_password: 'password'\n  # The auth token for Hipchat.\n\n# The directory from which notification templates are read.\ntemplates: \n- '/etc/alertmanager/template/*.tmpl'\n\n# The root route on which each incoming alert enters.\nroute:\n  # The labels by which incoming alerts are grouped together. For example,\n  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would\n  # be batched into a single group.\n  group_by: ['alertname', 'cluster', 'service']\n\n  # When a new group of alerts is created by an incoming alert, wait at\n  # least 'group_wait' to send the initial notification.\n  # This way ensures that you get multiple alerts for the same group that start\n  # firing shortly after another are batched together on the first \n  # notification.\n  group_wait: 30s\n\n  # When the first notification was sent, wait 'group_interval' to send a batch\n  # of new alerts that started firing for that group.\n  group_interval: 5m\n\n  # If an alert has successfully been sent, wait 'repeat_interval' to\n  # resend them.\n  repeat_interval: 3h \n\n  # A default receiver\n  receiver: webhook\n\n  # All the above attributes are inherited by all child routes and can \n  # overwritten on each.\n\n  # The child route trees.\n  routes:\n\n# Inhibition rules allow to mute a set of alerts given that another alert is\n# firing.\n# We use this to mute any warning-level notifications if the same alert is \n# already critical.\ninhibit_rules:\n- source_match:\n    severity: 'critical'\n  target_match:\n    severity: 'warning'\n  # Apply inhibition if the alertname is the same.\n  equal: ['alertname', 'cluster', 'service']\n\n\nreceivers:\n- name: 'webhook'\n  webhook_configs:\n  - url: 'http://127.0.0.1:8090/alert_webhook'\n\n```\n\n\talertmanager的配置中我们只需要注意两处，即全局配置的接收者webhook以及路由部分指定的唯一接受者为webhook，等会我们将使用一个微服务来示例如何通过webhook接受报警信息\n\n### 接着我们结合内置的web界面修改配置来看一下效果\n\n\t在graph导航中我们输入查询语句然后选择需要展示的时间段就有了下面的展示结果\n![这里写图片描述](http://img.blog.csdn.net/20180121121614013?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\t然后我们在status->targets导航中查看当前的targets状态，因为基本配置中只有一个并且属于在线状态所以就会有一下展示：\n\t\n![这里写图片描述](http://img.blog.csdn.net/20180121121842889?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n然后我们虚构一个端点信息，在基本配置的targets列表中添加一项：\n![这里写图片描述](http://img.blog.csdn.net/20180121122200407?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n然后使服务重新加载配置：\n\t\n\tcurl -XPOST http://192.168.0.77:9090/-/reload\n\n刷新targets对应的界面可以看到如下展示（以下为隔了几秒刷新出现的两个状态展示）\n\n![这里写图片描述](http://img.blog.csdn.net/20180121122310298?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n![这里写图片描述](http://img.blog.csdn.net/20180121122319860?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\t因为端点'localhost:9100'当前不存在所以状态最终为'DOWN'\n\n### 接下来我们上一个规则看一下效果\n要配置规则就必须要对应一定的指标，想知道有哪些指标可以访问以下链接所指：\n![这里写图片描述](http://img.blog.csdn.net/20180121122913614?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n首先我们先对条件做一个查询看一下图标信息：\n![这里写图片描述](http://img.blog.csdn.net/20180121123203845?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n然后我们来写规则，然后校验规则：\n\n```\n[root@vm7-1201-pure rules]# promtool check rules http_requests_total.yml \nChecking http_requests_total.yml\n  SUCCESS: 1 rules found\n\n[root@vm7-1201-pure rules]# cat http_requests_total.yml \ngroups:\n- name: http_requests_total\n  rules:\n  - alert: http_requests\n    expr: job:http_requests_total:mean5m{job=\"prometheus\"} > 900\n    for: 10m\n    labels:\n      severity: page\n    annotations:\n      summary: High request latency\n\n```\n\n因为当前没有重载使规则生效，所以界面上还是这样的\n![这里写图片描述](http://img.blog.csdn.net/20180121123836996?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n然后我们重新加载一下：\n\n\tcurl -XPOST http://127.0.0.1:9090/-/reload\n再来看一下界面：\n![这里写图片描述](http://img.blog.csdn.net/20180121124018307?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n当前的报警还未生效，然后我们一直刷新页面使http_requests_total的值上升到出发报警\n![这里写图片描述](http://img.blog.csdn.net/20180121125228021?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n这时候再去看alertmanager的状态，发现报警已经被接收到:\n![这里写图片描述](http://img.blog.csdn.net/20180121125407287?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
		'date':' on Feb 1, 2018'
	},
	'prometheus-4-mysql':{
		'title':'Monitor MySQL via Prometheus',
		'content':"##监控MySQL服务器\n\n**平台为redhat 7.2 x86_64bit**\n\n为了使监控可视化，我们将借助于Grafana，基本安装【略】，对于要监控的对象MySQL还需要安装mysqld_exporter【略】，本文假设安装就绪。\n\n监控配置的基本架构如下：\n![这里写图片描述](http://img.blog.csdn.net/20180122224803261?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n### 配置mysqld_exporter\n\n**增加一个用于监控的MySQL用户**\n\n\tmysql> GRANT REPLICATION CLIENT, PROCESS ON *.* TO 'mysqld_exporter'@'localhost' identified by 'redhat';\n\tmysql> GRANT SELECT ON performance_schema.* TO 'mysqld_exporter'@'localhost';\n\tmysql> flush privileges;\n\n指定mysqld_exporter连接MySQL的配置文件，当然首先要写配置文件，位置随便，如我的：\n\n```\n[root@prometheus ~]# cat /etc/prometheus/.my.cnf \n[client]\nuser=mysqld_exporter\npassword=redhat\n\n``` \n\n然后在mysqld_exporter的启动程序中指定\n\n```\n[root@prometheus ~]# systemctl status mysqld_exporter\n● mysqld_exporter.service - Prometheus exporter for MySQL server metrics.\n   Loaded: loaded (/usr/lib/systemd/system/mysqld_exporter.service; disabled; vendor preset: disabled)\n   Active: active (running) since Mon 2018-01-22 22:00:20 CST; 1h 47min ago\n     Docs: https://github.com/prometheus/mysqld_exporter\n Main PID: 2680 (mysqld_exporter)\n   CGroup: /system.slice/mysqld_exporter.service\n           └─2680 /usr/bin/mysqld_exporter -config.my-cnf=/etc/prometheus/.my.cnf###注意这里，需要修改Systemd服务把这一项加上\n\n```\n\n完成以上配置之后重启或者启动mysqld_exporter\n\n### 配置prometheus,加入mysql监控目标\n\n```\n[root@prometheus ~]# tail -n 12 /etc/prometheus/prometheus.yml | head -n 6\n  - job_name: 'mysql'\n    static_configs:\n      - targets: ['localhost:9104']\n        labels:\n          instance: 'mysql1'\n\n```\n\n配置完成重启或者reload prometheus服务\n\n\tcurl -XPOST http://ip:9090/-/reload\n\n### 下载并且配置监控模板\n\n\tgit clone https://github.com/percona/grafana-dashboards.git\n\tcp -r grafana-dashboards/dashboards /var/lib/grafana/\n\n**编辑Grafana配置文件如下：**\n\n```\n[root@prometheus ~]# sed -n '370,373p' /etc/grafana/grafana.ini \n[dashboards.json]\nenabled = true\npath = /var/lib/grafana/dashboards\n```\n\n然后重新启动或者启动grafana-server，在浏览器中输入http://ip:3000进行访问（用户密码默认admin）\n![这里写图片描述](http://img.blog.csdn.net/20180122230421259?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n可以看到我们导入的模板\n![这里写图片描述](http://img.blog.csdn.net/20180122230611221?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n**配置一下数据源为prometheus**\n点击最左上图标然后选中Data Sources-》add data datasource，然后按照以下内容填入\n![这里写图片描述](http://img.blog.csdn.net/20180122231054813?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n注意：\n\n\tType一定要是Prometheus\n\tURL是prometheus的端点url\n\tAccess选择proxy\n\t\n点击其中的MySQL Overview然后对查询条件做适当调整（点击每个图形的标题-》edit-》metrics）就会看到以下界面了：\n![这里写图片描述](http://img.blog.csdn.net/20180122230741570?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTG9ja2V5MjM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n",
		'date':' on Feb 1, 2018'
	}
}